{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd58cd8",
   "metadata": {},
   "source": [
    "<!-- use this command in cmd - spark-shell -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ae233e-0f7c-4884-9b69-55b37edd0ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Student|Subject|Grade|\n",
      "+-------+-------+-----+\n",
      "|  Alice|   Math|    A|\n",
      "|  Alice|Science|    A|\n",
      "|  Alice|English|    A|\n",
      "|    Bob|   Math|    B|\n",
      "|    Bob|Science|    B|\n",
      "|    Bob|English|    A|\n",
      "|Charlie|   Math|    B|\n",
      "|Charlie|Science|    B|\n",
      "|Charlie|English|    B|\n",
      "|  David|   Math|    A|\n",
      "|  David|Science|    A|\n",
      "|  David|English|    A|\n",
      "|    Eve|   Math|    B|\n",
      "|    Eve|Science|    A|\n",
      "|    Eve|English|    B|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StudentGrades\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample student scores\n",
    "scores = [\n",
    "    (\"Alice\", {\"Math\": 85, \"Science\": 90, \"English\": 80}),\n",
    "    (\"Bob\", {\"Math\": 70, \"Science\": 75, \"English\": 85}),\n",
    "    (\"Charlie\", {\"Math\": 60, \"Science\": 65, \"English\": 70}),\n",
    "    (\"David\", {\"Math\": 90, \"Science\": 95, \"English\": 85}),\n",
    "    (\"Eve\", {\"Math\": 75, \"Science\": 80, \"English\": 75})\n",
    "]\n",
    "\n",
    "# Create RDD from the scores\n",
    "scores_rdd = spark.sparkContext.parallelize(scores)\n",
    "\n",
    "# Define the grading scheme (example)\n",
    "grading_scheme = {\n",
    "    \"A\": (80, 100),\n",
    "    \"B\": (60, 79),\n",
    "    \"C\": (40, 59),\n",
    "    \"D\": (0, 39)\n",
    "}\n",
    "\n",
    "# Function to compute grades for a given score\n",
    "def compute_grade(score):\n",
    "    for grade, (lower_bound, upper_bound) in grading_scheme.items():\n",
    "        if lower_bound <= score <= upper_bound:\n",
    "            return grade\n",
    "    return \"F\"\n",
    "\n",
    "# Map operation to compute grades for each student\n",
    "grades_rdd = scores_rdd.map(lambda x: (x[0], {subject: compute_grade(score) for subject, score in x[1].items()}))\n",
    "\n",
    "# Convert RDD to DataFrame\n",
    "grades_df = spark.createDataFrame(grades_rdd.flatMap(lambda x: [(x[0], subject, grade) for subject, grade in x[1].items()]), [\"Student\", \"Subject\", \"Grade\"])\n",
    "\n",
    "# Display the result\n",
    "grades_df.show()\n",
    "\n",
    "# Stop SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b3f7c-99f7-414f-a5be-2aef637eff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession: This line imports the SparkSession class from the pyspark.sql module. SparkSession is the entry point to Spark SQL functionality and allows the creation and management of DataFrame objects.\n",
    "spark = SparkSession.builder \\ .appName(\"StudentGrades\") \\ .getOrCreate(): This code creates a SparkSession named \"StudentGrades\" if it doesn't already exist. The appName method sets the name of the application.\n",
    "scores: This variable holds sample student scores as a list of tuples. Each tuple contains a student's name as the first element and a dictionary representing subject scores as the second element.\n",
    "scores_rdd: This variable creates an RDD (Resilient Distributed Dataset) from the sample scores using parallelize. RDDs are the fundamental data structure in Spark.\n",
    "grading_scheme: This dictionary defines the grading scheme, mapping grade letters to score ranges.\n",
    "compute_grade: This function takes a score as input and computes the corresponding grade based on the grading scheme.\n",
    "grades_rdd: This variable applies a map operation to the scores_rdd, computing grades for each student's subject scores using the compute_grade function.\n",
    "grades_df: This variable converts the resulting RDD to a DataFrame using createDataFrame. It flattens the nested structure of the grades data and specifies column names as \"Student\", \"Subject\", and \"Grade\".\n",
    "grades_df.show(): This line displays the DataFrame containing the computed grades for each student and subject.\n",
    "spark.stop(): This line stops the SparkSession, releasing the resources associated with it.\n",
    "In summary, this code demonstrates how to compute student grades based on their subject scores using PySpark RDDs and then convert the result into a DataFrame for easy visualization and further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
